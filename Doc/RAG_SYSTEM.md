# ğŸ“š SystÃ¨me RAG (Retrieval-Augmented Generation)

Ce document dÃ©taille l'implÃ©mentation technique du systÃ¨me RAG dans WhytChat V1.

## ğŸ¯ Objectif

Le systÃ¨me RAG permet au modÃ¨le de langage (LLM) d'accÃ©der Ã  des donnÃ©es privÃ©es et spÃ©cifiques Ã  l'utilisateur qui ne font pas partie de son entraÃ®nement initial. Dans WhytChat, ce systÃ¨me est **local**, **privÃ©** et **isolÃ© par session**.

## ğŸ—ï¸ Architecture Technique

### 1. Stack Technologique

- **Base de DonnÃ©es Vectorielle** : [LanceDB](https://lancedb.com/) (EmbarquÃ©e, sans serveur).
- **ModÃ¨le d'Embedding** : `AllMiniLML6V2` via [fastembed-rs](https://github.com/Anush008/fastembed-rs).
  - _Dimension_ : 384
  - _Taille_ : ~23 MB (tÃ©lÃ©chargÃ© automatiquement au premier lancement).
  - _Performance_ : TrÃ¨s rapide sur CPU, idÃ©al pour une application desktop.

### 2. Isolation et Filtrage des DonnÃ©es

Contrairement Ã  beaucoup de systÃ¨mes RAG qui mÃ©langent toutes les donnÃ©es dans un index global, WhytChat implÃ©mente une **gestion granulaire par fichier**.

- Chaque chunk de texte ingÃ©rÃ© est taguÃ© avec une mÃ©tadonnÃ©e `metadata`: `file:{file_id}`.
- Les fichiers sont stockÃ©s dans une **Librairie Globale** (`library_files`) et peuvent Ãªtre liÃ©s Ã  plusieurs sessions.
- Lors de la recherche, un filtre strict est appliquÃ© sur les fichiers liÃ©s Ã  la session active : `WHERE metadata IN ('file:ID1', 'file:ID2', ...)`.
- **BÃ©nÃ©fice** : FlexibilitÃ© totale. Un mÃªme document peut Ãªtre utilisÃ© dans plusieurs contextes sans duplication, et les sessions ne voient que ce qui leur est explicitement liÃ©.

## ğŸ”„ Flux de DonnÃ©es

### A. Ingestion (Upload)

1.  **Upload UI** : L'utilisateur upload un fichier via la `DataSidebar`.
2.  **Stockage Fichier** : Le fichier original est sauvegardÃ© dans `data/library/{file_id}_{filename}`.
3.  **Enregistrement DB** : Une entrÃ©e est crÃ©Ã©e dans la table `library_files` (SQLite).
4.  **Liaison** : Le fichier est liÃ© Ã  la session courante via `session_files_link`.
5.  **Traitement (RagActor)** :
    - **Lecture** : Le contenu est lu en mÃ©moire.
    - **Chunking** : DÃ©coupage par sauts de ligne (`\n`) avec filtrage des lignes trop courtes (< 20 chars).
    - **Embedding** : Conversion des chunks en vecteurs (Float32Array[384]).
    - **Indexation** : Ã‰criture dans la table `knowledge_base` de LanceDB avec le tag `file:{id}`.

### B. RÃ©cupÃ©ration (Retrieval)

1.  **Message Utilisateur** : L'utilisateur envoie un message.
2.  **Analyse (Brain)** : Le systÃ¨me dÃ©termine si le RAG est nÃ©cessaire (`should_use_rag`).
3.  **RÃ©cupÃ©ration des IDs** : Le Supervisor rÃ©cupÃ¨re la liste des `file_ids` liÃ©s Ã  la session.
4.  **Recherche (RagActor)** :
    - La requÃªte utilisateur est vectorisÃ©e.
    - Recherche ANN (Approximate Nearest Neighbor) dans LanceDB.
    - **Filtre** : `metadata IN (file:id1, file:id2...)`.
    - **Limit** : Top 3 rÃ©sultats les plus proches.
5.  **Construction du Prompt** :
    - Les chunks trouvÃ©s sont concatÃ©nÃ©s.
    - Ils sont injectÃ©s dans le prompt systÃ¨me sous la section `Context:`.

## ğŸ’¾ SchÃ©ma de DonnÃ©es (LanceDB)

La table `knowledge_base` suit ce schÃ©ma Arrow :

| Champ      | Type               | Description                             |
| :--------- | :----------------- | :-------------------------------------- |
| `id`       | Utf8               | UUID unique du chunk.                   |
| `content`  | Utf8               | Le texte brut du chunk.                 |
| `metadata` | Utf8               | Tag de fichier (ex: `file:123-abc`).    |
| `vector`   | FixedSizeList<f32> | Le vecteur d'embedding (dim 384).       |

## ğŸš€ Performance & Optimisations

- **Cache LRU** : Les embeddings des requÃªtes frÃ©quentes sont mis en cache (taille 1000) pour Ã©viter de recalculer les vecteurs inutilement.
- **LanceDB** : Utilise un index sur disque optimisÃ©, permettant de gÃ©rer des millions de vecteurs sans charger toute la DB en RAM.

---

_Document gÃ©nÃ©rÃ© automatiquement - Novembre 2025_
